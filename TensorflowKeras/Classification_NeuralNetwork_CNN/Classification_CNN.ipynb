{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHHIXIPSyKZm"
      },
      "source": [
        "# Classification - CNN\n",
        "Utilizzeremo le **Convolutional Neural Network** (CNN) per la Classificazione di Animali Domestici.\n",
        "\n",
        "Utilizzeremo come *feature* i *pixel*, ovvero le immagini *raw* in formato RGB.\n",
        "\n",
        "Faremo uso del framework **TensorFlow** nella sua versione 2.x sfruttando l'API di alto livello **Keras** che semplifica la definizione di CNN profonde e rende disponibili numerosi modelli di reti pre-addestrate su *ImageNet*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS0NRhOHyKZn",
        "outputId": "300d8dbf-dd71-480c-e38b-d1ff5a526323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow Version 2.7.0\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import time, os, sys\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import Memory\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Nasconde messaggi di debug\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Rende visibile solo la GPU 0\n",
        "import tensorflow as tf\n",
        "print('Tensorflow Version', tf.__version__)\n",
        "\n",
        "import ml_visualization\n",
        "import ml_utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_8MyMByKZo"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "In questa esercitazione useremo un dataset composto di immagini di cani e gatti.\n",
        "\n",
        "Per caricare il dataset è necessario impostare:\n",
        "- il percorso in cui sono memorizzate le immagini del dataset (**db_path**);\n",
        "- il percorso di una cartella di lavoro (**exp_path**) dove, durante l'elaborazione, saranno memorizzati i file intermedi;\n",
        "- il percorso di una cartella (**checkpoints_path**) dove saranno memorizzati i modelli addestrati;\n",
        "- il percorso del file contenente la lista delle immagini e relative etichette di classe da utilizzare come *training set* (**train_filelist**);\n",
        "- il percorso del file contenente la lista delle immagini e relative etichette di classe da utilizzare come *test set* (**test_filelist**);\n",
        "- il percorso del file contenente la lista dei nomi delle classi (**label_filelist**).\n",
        "\n",
        "Di seguito sono rese disponibili le tre configurazioni utilizzate durante l'esercitazione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arP9DcTPyKZp",
        "outputId": "fb015027-4fef-4d03-a580-50894a0c2c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Caricamento in corso ...\n",
            "Caricate 650 immagini in 0.13 s.\n",
            "Gatto: 367\n",
            "Cane: 283\n"
          ]
        }
      ],
      "source": [
        "db_name = 'ml_bin' #'ml_bin' 'ml_multi'\n",
        "\n",
        "if db_name == 'ml_bin':\n",
        "    db_path = 'DBs/CaniGatti_ML18_Es8_2020' \n",
        "    train_filelist = 'BinaryTrainingSet.txt'\n",
        "    test_filelist = 'BinaryTestSet.txt'\n",
        "    label_filelist = db_path + '/BinaryLabels.txt'\n",
        "    class_num = 2   # caso 2 classi\n",
        "    validation_size = 200\n",
        "    test_has_labels = True\n",
        "elif db_name == 'ml_multi':\n",
        "    db_path = 'DBs/CaniGatti_ML18_Es8_2020'\n",
        "    train_filelist = 'MulticlassTrainingSet.txt'\n",
        "    test_filelist = 'MulticlassTestSet.txt'\n",
        "    label_filelist = db_path + '/MulticlassLabels.txt'\n",
        "    class_num = 12   # caso 12 classi - singoli animali\n",
        "    validation_size = 200\n",
        "    test_has_labels = False\n",
        "else:\n",
        "    raise ValueError('Database non valido.')\n",
        "\n",
        "checkpoints_path = './saved_models'\n",
        "exp_path = './exp_cache'\n",
        "\n",
        "# Predisposizione di un'area di caching su disco che velocizza la riesecuzione di chiamate di funzioni con gli stessi parametri\n",
        "memory = Memory(exp_path, verbose=0)  \n",
        "\n",
        "# Caricamento delle immagini\n",
        "print('Caricamento in corso ...')\n",
        "start = time.time()\n",
        "raw_images_x, label_y = ml_utilities.load_labeled_dataset(train_filelist, db_path, cache=memory)\n",
        "\n",
        "# Carica le etichette di classe\n",
        "label_names = [line.rstrip('\\n') for line in open(label_filelist,'r')]\n",
        "\n",
        "print('Caricate %d immagini in %.2f s.' % (len(raw_images_x), time.time() - start))\n",
        "for i in range(len(label_names)):\n",
        "    print('{}: {}'.format(label_names[i], np.count_nonzero(label_y == i)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2MWmFutyKZp"
      },
      "source": [
        "# Mobile Net\n",
        "\n",
        "Il modello di CNN (o meglio la famiglia di modelli di CNN) che utilizzeremo in questa esercitazione è noto come [**MobileNet V1**](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNet). Si tratta di un'architettura proposta da Google che garantisce performance di tutto rispetto (equiparabili a una GoogleNet) a un ragionevole costo computazionale, il che la rende particolarmente idonea ad operare in *inference* anche su architetture leggere (prive di GPU), come smartphone Android o iOS.\n",
        "\n",
        "A seconda del budget computazionale a disposizione, al modello base si può applicare:\n",
        "- un *resolution multiplier* che determina una riduzione sulla dimensione dell'immagine di input. Default = 224. Valori possibili: [224, 192, 160, 128] \n",
        "- un *depth multiplier* che opera una riduzione del numero di feature maps (canali) nei diversi layer, pari a una frazione di quelli del modello base. Default = 1. Valori possibili [1, 0.75, 0.50. 0.25]\n",
        "\n",
        "Per le piattaforme embedded sono disponibili anche versioni con quantizzazione *eight-bit fixed point* che riduce 4 volte l'occupazione di memoria rispetto a floting point 32 bit.\n",
        "\n",
        "*Keras* mette a disposizione funzioni semplificate per la creazione del grafo di MobileNet dati i moltiplicatori (resolution e depth). L'immagine di seguito mostra l'architettura della MobileNet V1 con depth e resolution multipliers impostati ai valori di default (1.0 e 224 rispettivamente)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL6rOM8ZyKZq"
      },
      "source": [
        "# Fine Tuning vs Addestramento da zero\n",
        "\n",
        "Un modello profondo e complesso come una MobileNet (28 layers, 4.2M parametri) non può essere efficacemente addestrato da zero (ovvero a partire da pesi casuali) utilizzando poche decine di migliaia di immagini.\n",
        "\n",
        "Infatti, specialmente per i livelli molto lontani dall'output che fungono come *feature extractors* iniziali, sono necessarie molte epoche su dataset con centinaia di migliaia di esempi.\n",
        "\n",
        "Possiamo però partire da un modello preaddestrato su ImageNet (caricandone i pesi) e modificandoli in base al training supervisionato del nostro problema. Questo approccio è noto come **Fine Tuning**.\n",
        "\n",
        "Bisogna però fare attenzione al fatto che il grafo originale del modello deve essere modificato, rimpiazzando il livello di output (*logit layer*) che originariamente aveva 1001 classi (le 1000 di ImageNet + 1 per la classe sconosciuta), in un nuovo livello di output con tanti neuroni quante sono le nuove classi. Solo per questo nuovo livello i pesi dovranno essere reinizializzati in modo casuale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBiTF1H4yKZq"
      },
      "source": [
        "# Creazione del grafo\n",
        "\n",
        "Vediamo ora come creare il grafo del modello e adattarlo per il Fine Tuning, con il supporto dell'API funzionale offerta da Keras.\n",
        "\n",
        "Nella seguente cella viene caricata la rete MobileNet con i pesi preaddestrati sul dataset ImageNet, viene definita la *loss* e l'ottimizzatore da utilizzare così come le principali metriche di classificazione. Si noti che la rete viene creata con il parametro *include\\_top* impostato a *False*. Questo significa che viene restituito un modello privato dell'ultimo layer della rete (che altrimenti presenterebbe 1000+1 output, pari al numero di classi in ImageNet).\n",
        "\n",
        "Il layer finale viene creato e agganciato nelle righe di codice immediatamente successive in modo da utilizzare un layer con tanti neuroni quante sono le classi del problema da risolvere.\n",
        "\n",
        "Infine vengono definite le funzioni che verranno utilizzate per svolgere i passi di addestramento e test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "VvfMggTnyKZq",
        "outputId": "0567474b-0b15-47c1-e9dd-7da27196c2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_5_0_128_tf_no_top.h5\n",
            "5578752/5577668 [==============================] - 0s 0us/step\n",
            "5586944/5577668 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mobilenet_version = 'small'  # 'small' 'default'\n",
        "\n",
        "if mobilenet_version == 'default':\n",
        "    image_side = 224\n",
        "    width_multiplier = 1.0\n",
        "elif mobilenet_version == 'small':\n",
        "    image_side = 128\n",
        "    width_multiplier = 0.5\n",
        "else:\n",
        "    raise ValueError('Versione di MobileNet non supportata.')\n",
        "\n",
        "# Definizione della shape dei tensori delle immagini\n",
        "#con 3 canali di colori 128x128x3\n",
        "IMG_SHAPE = (image_side, image_side, 3)\n",
        "\n",
        "# Creazione della rete\n",
        "base_model = tf.keras.applications.MobileNet(input_shape=IMG_SHAPE,\n",
        "                                             alpha=width_multiplier,\n",
        "                                             #include_top = False non tiene l'ultimo layer originale da 1000 classi\n",
        "                                             #a noi ci serve un layer da 2 neuroni (nel lab) e da 12 nella competizione\n",
        "                                             include_top=False,\n",
        "                                             pooling='avg',\n",
        "                                             weights='imagenet')\n",
        "\n",
        "# Se trainable è uguale a False i pesi della rete sono congelati\n",
        "# In questo caso vogliamo permettere l'addestramento dei pesi\n",
        "base_model.trainable = True\n",
        "\n",
        "# Definisce la loss\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Definisce l'ottimizzatore\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0025)\n",
        "\n",
        "# Le metriche offerte da Keras accumulano i valori su più batch\n",
        "# Loss media sul training set\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')  \n",
        "# Accuratezza sul training set\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')  \n",
        "\n",
        "# Loss media sul validation/test set\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "# Accuratezza sul validation/test set\n",
        "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "# Adatta la rete usando Functional API di Keras\n",
        "#placeholder (finto layer) che fa da input \n",
        "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "#placeholder per l'output (feature -> output del modello nn ancora passato dal layer di classificazione)\n",
        "feature = base_model(inputs)\n",
        "#in questo caso due ma saranno 12 poi\n",
        "dense_layer = tf.keras.layers.Dense(class_num)\n",
        "#due logits prima 12 poi\n",
        "logits = dense_layer(feature)\n",
        "softmax_layer = tf.keras.layers.Softmax()\n",
        "probs = softmax_layer(logits)\n",
        "#creo effettivamente il modello sà che deve prendere gli input e output di una certa shape\n",
        "model = tf.keras.Model(inputs=inputs, outputs=[logits, probs])\n",
        "\n",
        "# NOTA: non viene chiamata la funzione .compile di Keras in\n",
        "# quanto eseguiamo il training a più basso livello senza \n",
        "# utilizzare la funzione .fit\n",
        "\n",
        "# Funzione di train su un minibatch (iterazione)\n",
        "#i decoratori dicono a tensorflow che deve crearsi dei grafici ottimizzati\n",
        "#questo lo fa solo la prima volta, dalla seconda volta in poi grazie a questo grafo è molto più efficente e veloce\n",
        "#una volta ottimizzato però non è facile da debuggare perchè il codice ottimizzato non sarà più visibile\n",
        "#perchè il codice sarà più \"normale\" ma trasformato in un grafo\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    #comincia a tenerti questo tape che tiene traccia del gradiente\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits, _ = model(images, training=True)\n",
        "        loss = loss_object(labels, logits)\n",
        "    #backpropagation del gradiente\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    #ottimizzatore applica il gradiente per aggiornare i pesi\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    # Le metriche accumulano i valori (fino a chiamata di reset)\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, logits)\n",
        "\n",
        "# Funzione di inference su un minibatch    \n",
        "#parte dalle x (images) e dalle y (labels)\n",
        "#traing=False, stiamo facendo inference quindi non train\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    logits, probs = model(images, training=False)\n",
        "    v_loss = loss_object(labels, logits)\n",
        "    # Le metriche accumulano i valori (fino a chiamata di reset)\n",
        "    val_loss(v_loss)\n",
        "    val_accuracy(labels, logits) \n",
        "    return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6iPt20uyKZr"
      },
      "source": [
        "È possibile visualizzare il modello risultante delle operazioni di caricamento e modifica della rete utilizzando il metodo **.summary()**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB2bCoWzyKZr",
        "outputId": "eebf8584-054a-46fa-888a-164f102d05ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " mobilenet_0.50_128 (Functio  (None, 512)              829536    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 1026      \n",
            "                                                                 \n",
            " softmax (Softmax)           (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 830,562\n",
            "Trainable params: 819,618\n",
            "Non-trainable params: 10,944\n",
            "_________________________________________________________________\n",
            "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
          ]
        }
      ],
      "source": [
        "# base_model.summary()  # Modello prima delle modifiche\n",
        "\n",
        "model.summary()\n",
        "#tf.keras.utils.plot_model(model, 'mymodel.png', show_shapes=True) # Richiede pydot e graphviz, opzionale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLnWxcK1yKZr"
      },
      "source": [
        "# Resizing e Suddivisione in Training e Validation Set\n",
        "\n",
        "Ora che è stato definito il modello da utilizzare è possibile processare il dataset per portare le immagini alla dimensione desiderata (*image\\_side*) e per ottenere un validation set separato. La cella seguente mostra come suddividere il dataset in training e validation set utilizzando [**train_test_split**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) mentre il ridimensionamento delle immagini è affidato alla funzione *resize\\_images* già vista nelle precedenti esercitazioni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-9KorgnyKZs",
        "outputId": "928fac28-b42b-43e4-9d36-abc0c3088141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resizing in corso ...\n",
            "Resizing completato in 4.94 s.\n",
            "Numero di pattern nel training set: 450\n",
            "Numero di pattern nel validation set: 200\n"
          ]
        }
      ],
      "source": [
        "print('Resizing in corso ...')\n",
        "start = time.time()\n",
        "resized_image_x = ml_utilities.resize_images(raw_images_x, image_side, image_side, cache=memory)\n",
        "print('Resizing completato in %.2f s.' % (time.time() - start))\n",
        "\n",
        "train_x, validation_x, train_y, validation_y = train_test_split(resized_image_x, label_y,\n",
        "                                                                test_size=validation_size,\n",
        "                                                                #con stratify cercherà di fare lo split in modo da conservare lo split\n",
        "                                                                #delle classi (il bilanciamento delle classi RICORDATI CHE CI SONO PIù GATTI CHE CANI)\n",
        "                                                                #stratify è importante su un dataset piccolino\n",
        "                                                                stratify=label_y,\n",
        "                                                                random_state=1234)\n",
        "\n",
        "print('Numero di pattern nel training set:', len(train_x))\n",
        "print('Numero di pattern nel validation set:', len(validation_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne5ZUS_nyKZs"
      },
      "source": [
        "# Creazione del Dataset TF 2.x\n",
        "\n",
        "TensorFlow mette a disposizione la classe [**Dataset**](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) in grado di semplificare diverse operazioni di caricamento e manipolazione del dataset. Uno dei metodi più semplici per create un Dataset di TensorFlow è quello di utilizzare la funzione [**from\\_tensor\\_slices**](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) che trasforma dei tensori NumPy in un Dataset dal medesimo contenuto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGJ_itxcyKZs"
      },
      "outputs": [],
      "source": [
        "training_set = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "validation_set = tf.data.Dataset.from_tensor_slices((validation_x, validation_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7aw1-KdyKZs"
      },
      "source": [
        "## Suddivisione in minibatch\n",
        "\n",
        "Una volta applicate le procedure di caricamento, di augmentation e finalizzata la suddivisione di training e validation set è possibile, grazie alle funzionalità della classe Dataset, definire la suddivisione in minibatch.\n",
        "\n",
        "La cella seguente mostra come utilizzare il metodo **.batch(...)** per ottenere un dataset che resituirà un numero di pattern pari a *minibatch\\_size* a ogni iterazione. I Dataset di TensorFlow infatti, se non configurati diversamente, restituiscono singoli pattern.\n",
        "\n",
        "I dataset *train\\_dataset* e *valid\\_dataset* creati nella seguente cella resituiranno a ogni iterazione un numero di pattern pari a *minibatch\\_size*. Le immagini contenute in ogni minibatch verranno unite in un unico tensore di dimensione *(minibatch\\_size, image\\_side, image\\_side, 3)*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEBzfKp1yKZs"
      },
      "outputs": [],
      "source": [
        "minibatch_size = 50\n",
        "\n",
        "#se rimane un minibatch con meno di 50 pattern lo droppa, durante il training può dar fastidio\n",
        "#cercare di non fare delle frazioni. In questo caso con 450 elementi e 200 elementi nei due set di dati, non ci sono frazioni\n",
        "train_dataset = training_set.batch(minibatch_size, drop_remainder=True) \n",
        "valid_dataset = validation_set.batch(minibatch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtYuSSaFyKZt"
      },
      "source": [
        "# Addestramento\n",
        "Ora siamo pronti per il *training*. La cella seguente esegue l'addestramento della MobileNet per un numero di epoche pari a **n_epochs** utilizzando minibatch di dimensione **minibatch_size**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "fac8100LyKZt",
        "outputId": "ad243ca2-90aa-4faa-9966-fa89e0057425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "Epoch 1  ."
          ]
        }
      ],
      "source": [
        "# Attenzione: eseguire questa cella più volte significa riprendere\n",
        "# l'addestramento da dove era stato lasciato, cioè non ricomincia\n",
        "# ogni volta dai pesi iniziali!\n",
        "n_epochs = 2\n",
        "   \n",
        "epochs_training_loss = []\n",
        "epochs_validation_accuracy = []\n",
        "epochs_training_accuracy = []\n",
        "\n",
        "t_start = time.time()\n",
        "print(\"Start Training\")\n",
        "\n",
        "total_train_patterns = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    #vogliamo calcolare le epoche per ogni epoca corrente\n",
        "    #resetta le metriche all'inizio\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    val_loss.reset_states()\n",
        "    val_accuracy.reset_states()\n",
        "    \n",
        "    print(\"Epoch\", epoch + 1, \" \", end=\"\")\n",
        "    \n",
        "    # Train su tutti i minibatch dell'epoca\n",
        "    #traina su quei 50 pattern ogni volta\n",
        "    for X_minibatch, y_minibatch in train_dataset:\n",
        "        total_train_patterns += len(X_minibatch)\n",
        "        print(\".\", end=\"\", flush = True)\n",
        "        train_step(X_minibatch, y_minibatch)  \n",
        "    \n",
        "    # Evaluation\n",
        "    for X_minibatch, y_minibatch in valid_dataset:\n",
        "        print(\"+\", end=\"\", flush = True)\n",
        "        test_step(X_minibatch, y_minibatch)\n",
        "        \n",
        "    epochs_training_loss.append(train_loss.result().numpy())\n",
        "    epochs_training_accuracy.append(train_accuracy.result().numpy() * 100)\n",
        "    epochs_validation_accuracy.append(val_accuracy.result().numpy() * 100)\n",
        "\n",
        "    print(\"  Train loss: %.4f  Train acc: %.2f %%  Validation acc: %.2f %%\" % (train_loss.result(), train_accuracy.result() * 100, val_accuracy.result() * 100))\n",
        "\n",
        "print('Salvataggio del modello...')\n",
        "# Salva tutto: pesi, ottimizzatore, ecc.\n",
        "save_path = str(Path(checkpoints_path) / (\"dogcat_model_%s_with_%d_classes\" % (db_name, class_num)))\n",
        "\n",
        "# .save() può restituire dei warning relativi alla deprecazione di alcune componenti\n",
        "# interne di TensorFlow. Si tratta di un bug già sistemato nelle versioni nightly\n",
        "# e che scomparirà nelle prossime versioni.\n",
        "model.save(save_path)\n",
        "\n",
        "t_elapsed = time.time()-t_start\n",
        "print (' -> %d patterns (%.2f sec.) -> %.2f patt/sec' % (total_train_patterns, t_elapsed, total_train_patterns / t_elapsed))\n",
        "\n",
        "ml_visualization.plot_performance_curves(epochs_training_loss, epochs_training_accuracy, epochs_validation_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNXNywz3yKZt"
      },
      "source": [
        "La cella seguente mostra come costruire la *Confusion Matrix* per il validation set. Il codice della cella seguente mostra come eseguire un'epoca sul validation set memorizzandone i risultati. I risultati vengono successivamente utilizzati per disegnare la matrice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfmT1QL2yKZt"
      },
      "outputs": [],
      "source": [
        "first_minibatch = True\n",
        "for X_minibatch, y_minibatch in valid_dataset:\n",
        "    minibatch_probs = test_step(X_minibatch, y_minibatch)\n",
        "    if first_minibatch:\n",
        "        valid_probs = minibatch_probs.numpy()\n",
        "        first_minibatch = False\n",
        "    else:\n",
        "        valid_probs = np.concatenate((valid_probs, minibatch_probs))\n",
        "\n",
        "# argmax permette di ottenere l'etichetta di classe con \n",
        "# punteggio più alto per tutti i pattern\n",
        "predicted_y = valid_probs.argmax(axis=1)\n",
        "ml_visualization.plot_confusion_matrix(validation_y, predicted_y, label_names, figsize=(10,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh-HCptcyKZu"
      },
      "source": [
        "\n",
        "# Tuning degli iperparametri\n",
        "\n",
        "Per il solo problema binario si provi a intervenire sugli iperparametri nel seguente ordine:\n",
        "- aumentare/diminuire il numero di epoche (**n_epochs**) per garantire convergenza evitando al tempo stesso overfitting;\n",
        "- tarare il *learning rate* (**learning_rate** nella sezione [Creazione del grafo](#Creazione-del-grafo));\n",
        "- provare un diverso Optimizer (es. [**Adam**](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) nella sezione [Creazione del grafo](#Creazione-del-grafo));\n",
        "\n",
        "\n",
        "## Salvataggio del modello migliore\n",
        "Si consiglia di modificare il codice della cella precedente per poter salvare ad ogni epoca il modello ottenuto (solamente se l'accuratezza di validation è maggiore della massima incontrata fino a quel momento). In questo modo alla fine della fase di *train* il modello salvato sarà il migliore anche se avete impostato un numero di epoche maggiore di quello ottimale.\n",
        "\n",
        "NOTA: il modello viene salvato con un nome diverso a seconda del tipo di problema affrontato (binario, multiclasse).\n",
        "\n",
        "## Test\n",
        "\n",
        "Per il problema binario sono fornite le etichette di classe per il test set. la seguente cella misura l'accuratezza della miglior soluzione ottenuta (utilizzando il modello salvato al passo precedente) sul dataset di test per verificarne l'effettiva capacità di generalizzazione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sblKuh-yKZu"
      },
      "outputs": [],
      "source": [
        "minibatch_size_test = 50\n",
        "\n",
        "if not test_has_labels:\n",
        "    # Non sono fornite etichette per il problema di classificazione sui singoli animali\n",
        "    raise ValueError('Il test set per il problema scelto non ha etichette di classe')\n",
        "    \n",
        "raw_test_images_x, test_y = ml_utilities.load_labeled_dataset(test_filelist, db_path, cache=memory)\n",
        "resized_test_image_x = ml_utilities.resize_images(raw_test_images_x, image_side, image_side, cache=memory)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((resized_test_image_x, test_y))\n",
        "test_dataset = test_dataset.batch(minibatch_size_test, drop_remainder=False)\n",
        "\n",
        "# Carica il modello salvato in precedenza su disco.\n",
        "# Attenzione: se questa istruzione restituisce un errore\n",
        "# è possibile commentarla e utilizzare il modello\n",
        "# già memorizzato nella variabile \"model\". In alternativa\n",
        "# è possibile aggiornare a TensorFlow 2.2.0 o superiore.\n",
        "model = tf.keras.models.load_model(save_path)\n",
        "\n",
        "print(\"Computing Accuracy on the Test Set \", end=\"\" )\n",
        "t_start = time.time()\n",
        "\n",
        "# Riutilizziamo gli oggetti metrics usati per il validation set\n",
        "val_loss.reset_states()\n",
        "val_accuracy.reset_states()\n",
        "\n",
        "first_minibatch = True\n",
        "for X_minibatch, y_minibatch in test_dataset:\n",
        "    minibatch_probs = test_step(X_minibatch, y_minibatch)\n",
        "    if first_minibatch:\n",
        "        test_probs = minibatch_probs.numpy()\n",
        "        first_minibatch = False\n",
        "    else:\n",
        "        test_probs = np.concatenate((test_probs, minibatch_probs))\n",
        "        \n",
        "print(\" %.2f %%\" % (100 * val_accuracy.result()))\n",
        "t_elapsed = time.time()-t_start\n",
        "print (' -> %d patterns (%.2f sec.) -> %.2f patt/sec' % (len(test_y), t_elapsed, len(test_y) / t_elapsed))\n",
        "\n",
        "predicted_y = test_probs.argmax(axis=1)\n",
        "print(predicted_y.shape, test_y.shape)\n",
        "ml_visualization.plot_confusion_matrix(test_y, predicted_y, label_names, figsize=(10,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Dp5XXvyKZu"
      },
      "source": [
        "## Visualizzazione errori\n",
        "La cella seguente permette di visualizzare le immagini di test che la rete classifica erroneamente. Sopra ad ogni immagine è riportato il nome della classe corretta mentre a lato le classi più probabili."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "UL8_LNeUyKZu"
      },
      "outputs": [],
      "source": [
        "errors = predicted_y != test_y\n",
        "error_idx = np.where(errors == True)[0]\n",
        "\n",
        "# Visualizzazione immagini\n",
        "image_per_row = min(3, len(error_idx))\n",
        "top_class_count = 3\n",
        "max_images = min(30, len(error_idx))\n",
        "\n",
        "row_count = math.ceil(max_images / image_per_row)\n",
        "column_count = image_per_row\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "_, axs = plt.subplots(row_count, column_count, figsize=(15, 4*row_count), squeeze=False)\n",
        "\n",
        "for i in range(row_count):\n",
        "    for j in range(column_count):\n",
        "        axs[i,j].axis('off')\n",
        "\n",
        "for i in range(max_images):\n",
        "    q = i//image_per_row\n",
        "    r = i%image_per_row\n",
        "    idx = error_idx[i]\n",
        "    axs[q,r].imshow(resized_test_image_x[idx])\n",
        "    axs[q,r].set_title(label_names[test_y[idx]])\n",
        "    \n",
        "    sorted_test_probs, sorted_label_names= (list(t) for t in zip(*sorted(zip(test_probs[idx], label_names))))\n",
        "    text=''\n",
        "    for j in range(min(top_class_count,class_num)):\n",
        "        text+='{}: {:.2f}\\n'.format(sorted_label_names[-j-1],sorted_test_probs[-j-1])\n",
        "    \n",
        "    axs[q,r].text(resized_test_image_x[idx].shape[1]*1.05, resized_test_image_x[idx].shape[0]*0.5, text, horizontalalignment='left', verticalalignment='center')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}